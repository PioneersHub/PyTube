{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Release Conference Videos on YouTube","text":"<p>Manage and release conference videos on YouTube using the talk and speaker infos in Pretalx</p>"},{"location":"#main-features","title":"Main Features","text":"<ul> <li>Manage the release of videos on YouTube:<ul> <li>Video descriptions</li> <li>Publishing date</li> <li>Monitoring of the release status and triggering of Social Media posts</li> <li>Management of videos in multiple channels</li> </ul> </li> <li>Create descriptions based on the data in Pretalx with NLP</li> <li>Create and post Social Media posts</li> <li>Email notifications to speakers</li> </ul>"},{"location":"#high-level-process-overview","title":"High level process overview","text":"<ol> <li>Involve your video recording team from the very start</li> <li>Upload videos to YouTube</li> <li>Collect data from Pretalx, store local JSON files <code>records</code></li> <li>Add descriptions to <code>records</code> via Natural Language Processing (NLP).`</li> <li>Process <code>records</code> to <code>video metadata</code> incl. publishing date, store in directory <code>video_records</code></li> <li>Update videos via API on YouTube with <code>video metadata</code>: move to <code>video_records_updated</code></li> <li>Confirm recently published videos: move to <code>video_published</code> and create Social Media posts and Email notifications</li> <li>Send out Social Media posts and Emails</li> </ol> <p>\u26a0\ufe0f Note: You need to follow a few conventions to make everything work seamlessly. Best familiarize yourself with the process upfront.</p>"},{"location":"#simplified-graph-of-the-process","title":"Simplified graph of the process","text":"<pre><code>graph LR;\n\n    P[1 Pretalx];\n    R[2 Records];\n    N[3 descriptions];\n    V[4 Video metadata];\n    F((Process));\n    G((Process));\n    H((Process));\n    VS[5 YouTube];\n    S[6 Post/Email];\n    X((End));\n    P --&gt; R;\n    R --&gt; N --add --&gt; R;\n    F --process--&gt; R;\n    F --create---&gt; V;\n    G --check ready--&gt; V;\n    G --update--&gt; VS;\n    H --check done--&gt; VS;\n    H --send--&gt; S;\n    S --&gt; X;\n</code></pre>"},{"location":"#conventions","title":"Conventions","text":"<p>For file naming, always use the Pretix-ID is used.</p> <p>For each status a separate directory is used. Move the files to the next status directory after successful processing.</p>"},{"location":"#preparations","title":"Preparations","text":"<p>Involve your video recording team from the very start. It's a best practice to have a production plan.</p> <p>The current implementation provides an interface to Google Sheets to get data from a production plan shared on Google Drive. The production plan must include information for linking the video recording files to the Pretalx Id.</p> <p>Upload videos to YouTube, for instructions details see here.</p>"},{"location":"#configration","title":"Configration","text":"<p>There is a general configuration file <code>config.yaml</code> that provides the general structure.</p> <p>Individual configurations are stored in the local file <code>config_local.yaml</code> which must never be shared:</p> <ul> <li>Storage locations</li> <li>Pretalx<ul> <li>Event information</li> <li>Custom assignments of Pretalx ID to a release channel (e.g., PyCon DE / PyData)</li> </ul> </li> <li>YouTube<ul> <li>credentials</li> <li>channels</li> </ul> </li> <li>OpenAI: credentials</li> <li>Other:<ul> <li>Vimeo API access (optional)</li> <li>Google Spreadsheets (optional). Often used for managing custom information like opt-outs.</li> </ul> </li> </ul> <p>Note</p> <p>Pretalx access is provided via <code>pythanis</code> which stores the credentials in a separate local file</p>"},{"location":"#credentials-for-pythanis","title":"Credentials for Pythanis","text":"<p>Pretalx is used to interact with:</p> <ol> <li>Pretalx</li> <li>Google Spreadsheets</li> <li>Helpdesk (to send Emails)</li> </ol> <p>See here how to add credentials.</p>"},{"location":"#limitations","title":"Limitations","text":"<p>Currently, a local storage is required for storage of metadata and managing the release status. A future version should support a shared space or document database.</p> <p>Sending Emails is currently only supported via the Helpdesk API. Other ways to send emails should be supported in the future.</p>"},{"location":"#realization","title":"Realization","text":"<p>Pioneers Hub helps to build and maintain thriving communities of experts in tech and research to share knowledge, collaborate and innovate together. </p>"},{"location":"emails/","title":"E-Mails","text":"<p>Speakers receive an email once the YouTube video is published.</p> <p>Currently, the email is sent via Helpdesk, see <code>pythanis</code>.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#environment","title":"Environment","text":"<p>This project uses Pixi for package management. Pix supports Windows, MacOS, and Linux. See the Pixi documentation for more information how to install pixi.</p> <p>To install the environment, run the following command for the project root directory:</p> <pre><code>pixi install\n</code></pre>"},{"location":"installation/#documentation","title":"Documentation","text":""},{"location":"installation/#preview","title":"Preview","text":"<p>Run <pre><code>mkdocs serve\n</code></pre> to start the live-reloading docs server.</p> <p>The local website is run on http://127.0.0.1:8000/pytube/</p> <p>MacOS-Error </p> <p>no library called \"cairo-2\" was found\u2026</p> <p>can be fixed with: <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\nmkdocs serve\n</code></pre> See here for details</p>"},{"location":"installation/#publishing","title":"Publishing","text":"<p>The documentation website is hosted at GitHub pages.</p> <p>To deploy: <pre><code>mkdocs gh-deploy\n</code></pre></p> <p>MacOS-Error</p> <p>no library called \"cairo-2\" was found\u2026</p> <p>can be fixed with: <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\nmkdocs gh-deploy\n</code></pre></p> <p>before running <code>mkdocs gh-deploy</code> to install the cairo library.</p>"},{"location":"installation/#versioning-schema","title":"Versioning Schema","text":"<p>The versioning schema is <code>{major}.{minor}.{patch}[{release}{build}]</code> where the latter part (release and build) is optional.</p> <p>It is recommended to do <code>--dry-run</code> prior to your actual run.</p> <pre><code># increase version identifier\nbumpversion [major/minor/patch/release/build]  # --verbose --dry-run\n\n# e.g.\nbumpversion minor  # e.g. 0.5.1 --&gt; 0.6.0\nbumpversion minor --new-version 0.7.0  # e.g. 0.5.1 --&gt; 0.7.0\n</code></pre>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2024 Pioneers Hub gemeinn\u00fctzige GmbH (non-profit)</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p> <p>RESTRICTED LICENSE FOR COMPANY LOGO</p> <p>The \"Pioneers Hub\" logo, as provided in this repository (the \u201cLogo\u201d), is the exclusive property of Pioneers Hub gGmbH. By using the Logo, you agree to the following terms:</p> <ol> <li>Permitted Use:     You are allowed to use the Logo only for purposes related to promoting Pioneers Hub\u2019s official projects or repositories.     You must give appropriate credit to Pioneers Hub when using the Logo in any form.</li> <li>Prohibited Use:     You are not allowed to use the Logo for any commercial purposes without prior written permission from Pioneers Hub.     You cannot modify, distort, or alter the Logo in any way that could cause confusion or misrepresentation of Pioneers Hub.     The Logo may not be used in any way that suggests endorsement by Pioneers Hub of any other product, service, or entity unless expressly permitted in writing.</li> <li>Redistribution:     You are not permitted to redistribute the Logo, either on its own or as part of any other project or product, without prior written consent from Pioneers Hub.</li> <li>Termination of Use:     Pioneers Hub reserves the right to request the removal or alteration of the Logo\u2019s use at any time for any reason. Upon such a request, you must comply immediately.</li> <li>Ownership:     The Logo is protected by copyright, trademark, and other applicable laws. Use of the Logo does not grant any ownership or rights over the Logo to you or any other third party.</li> </ol>"},{"location":"linkedin/","title":"LinkedIn-Posts","text":"<p>API access needs to be requested. The API is not available for all accounts. The LinkedIn API can be very confusing. The documentation is not very clear and there are multiple versions and different endpoints for different purposes which is not intuitive nor obvious.</p>"},{"location":"linkedin/#apps-products","title":"Apps / Products","text":"<p>Request both</p> <ul> <li>Share on LinkedIn</li> <li>Register a new app</li> </ul> <p>Token generator for ACCESS_TOKEN and REFRESH_TOKEN: https://www.linkedin.com/developers/tools/oauth/token-generator?</p> <p>Blogposts: https://blog.futuresmart.ai/how-to-automate-your-linkedin-posts-using-python-and-the-linkedin-api https://towardsdatascience.com/linkedin-api-python-programmatically-publishing-d88a03f08ff1 https://www.jcchouinard.com/linkedin-api-how-to-post/</p>"},{"location":"openai/","title":"NLP Services","text":"<p>The OpenAI API is used to generate descriptions from the information retrieved from Pretalx.</p> <p>Attributes added to the session records:</p> Record Description sm_teaser_text A short engaging text with about 50 tokens sm_short_text A short description with about 100 tokens sm_long_text A short description with about300 tokens"},{"location":"openai/#setup","title":"Setup","text":"<p>Add your API key for Open AI to <code>config_local.yaml</code>.</p> <pre><code>openai:\n  api_key: \"your-api-key...\"\n</code></pre> <p>The API key can be found in your OpenAI account</p>"},{"location":"openai/#prompts","title":"Prompts","text":"<p>Prompts can be adjusted in the config. Add custom prompts to <code>config_local.yaml</code>.</p> <pre><code>prompts:\n  teaser: &gt;\n    You are an expert editor and your task is to write one short teaser sentence to encourage people to watch\n    the video based on the title and text.  The teaser should be a short sentence that is catchy and engaging.\n    Use a professional tone. Start with 'Watch'.\n  # note there is a placeholder to instruct about the desired the length: {max_tokens}\n  description: &gt;\n    You are an expert editor and your task is to create a continuous text with about {max_tokens} tokens.\n    The text describes the talk and should be concise and informative please. Mention the speaker names,\n    jobs and companies. Never use the verb 'delve'. Make sure only to mention jobs and companies\n    if they are mentioned in the text. \n</code></pre>"},{"location":"openai/#alternatives","title":"Alternatives","text":"<p>Other LLMs can be used via monkey patching <code>teaser_text</code> and <code>sized_text</code> in the <code>nlpserice</code> module.</p>"},{"location":"processing/","title":"Processing Pipeline","text":"<p>For each video a record is created.</p>"},{"location":"processing/#detailed-graph-of-the-process","title":"Detailed graph of the process","text":""},{"location":"processing/#collecting-data-from-pretalx","title":"Collecting data from Pretalx","text":"<p>The data from Pretalx is collected via the <code>pythanis</code> library.</p> <p>In <code>/records</code> the data is stored in JSON files named {pretalx id}.json.</p> <pre><code>graph LR;\n\n    P1[Pretalx-API Sessions];\n    P2[Pretalx-API Speakers];\n    R[(/records)];\n    N[NLP Service];\n    F((Records));\n    P1 &amp; P2 --load_all_confirmed_sessions, load_all_speakers, create_records--&gt; F;\n    F --- R;\n    F --add_descriptions--&gt; N;\n    N --update--&gt; R;    </code></pre>"},{"location":"processing/#create-video-descriptions","title":"Create Video Descriptions","text":"<p>The video descriptions are created from the records.</p> <p><pre><code>graph LR;\n\n    R[(Records)];\n    V[(/video_records)];\n    V2[(/\u2026_records_updated)];\n    F((\"PrepareVideo\n    Metadata\"));\n    F --- R;  \n    F -- make_all_video_metadata, update_publish_dates --&gt; V;  \n    F -- send_all_video_metadata --&gt; V2; \n    V -.move.- V2; </code></pre> Caveats:  - Scheduled videos need to be set 'private' (cannot be 'unlisted').</p>"},{"location":"processing/#youtube-check-notification","title":"YouTube Check &amp; Notification","text":"<p>The videos have a publishing date set. We need to monitor the release status and trigger Social Media posts and emails to the speakers.</p> <pre><code>graph LR;\n\n    V2[(/\u2026_records_updated)];\n    V3[(/video_published)];\n    F((\"Publisher\"));\n    VS[YouTube];\n    S[(/speaker_to_email)];\n    L[(/linked_in_to_post)];\n    C{online?};\n    F -- check_status --&gt; VS;\n    V2 -.move.- V3;\n    F -- process_recent_video_releases -&gt; V2; \n    VS --&gt; C --&gt; |prepare_email| S;\n    VS --&gt; C --&gt; |prepare_linkedin_post| L;\n    VS --&gt; C -.-&gt; |move| V2;</code></pre> <p>In the final step send Social Media posts and emails to the speakers.</p> <pre><code>graph LR;\n\n    F((\"Publisher\"));\n    S[(/speaker_to_email)];\n    S2[(/speaker_to_email)];\n    L[(/linked_in_to_post)];\n    L2[(/linked_in_to_post)];\n    F -- post_on_linked_id --&gt; L;\n    F -- email_speakers --&gt; S;\n    S -.move.- S2;\n    L -.move.- L2;\n</code></pre>"},{"location":"scripts/","title":"Scripts","text":"<p>Scripts are used to run the jobs in the processing pipeline. They are located in the <code>scripts</code> directory.</p>"},{"location":"scripts/#pre-processing-metadata-to-records","title":"Pre-Processing Metadata to <code>Records</code>","text":"<p>For each video a record is created. The record is a dictionary that contains all the metadata for a video. The record is then used to create the video description and the video itself.</p> <pre><code>from pytube.handlers import Records\nfrom pytube import conf\n\n# custom questions mapping\nquestions_map = conf.pretalx_questions_map\n\nr = Records(qmap=questions_map)\nr.load_all_confirmed_sessions()\nr.load_all_speakers()\nr.create_records()\nr.add_descriptions(replace=False)\n</code></pre>"},{"location":"scripts/#create-video-descriptions","title":"Create Video Descriptions","text":"<p>The video descriptions are created from the records. This can be done in multiple steps at once or individually. The methods update the records and their file location (status) accordingly.</p> <pre><code>from datetime import UTC, datetime, timedelta\n\nfrom handlers.youtube import PrepareVideoMetadata\n\nfrom pytube import conf\n\nmeta = PrepareVideoMetadata(\"jinjs2_template.txt\", \"Great Conference Name\")\nmeta.make_all_video_metadata()\nmeta.update_publish_dates(states=['video_records', 'video_records_updated'],\n                          start=datetime.now(tz=UTC) + timedelta(minutes=5), delta=timedelta(hours=4))\nfor channel in conf.youtube.channels:\n    meta.send_all_video_metadata(destination_channel=channel)\n</code></pre> <p>More about scheduling videos can be found here.</p>"},{"location":"scripts/#notify","title":"Notify","text":"<p>A script that should be run regularly until all videos are published.</p> <ol> <li>Check for recent video releases on the YouTube channel.</li> <li>Trigger LinkedIn posts and emails to speaker creation for all videos published since the last run.</li> <li>Post on LinkedIn</li> <li>Send emails to speakers</li> </ol> <p>Run <code>scripts/notify.py</code></p>"},{"location":"scripts/#other-scripts","title":"Other Scripts","text":"<p>The <code>scripts</code> directory contains additional scripts for various tasks, feel free to explore them.</p>"},{"location":"youtube/","title":"YouTube","text":"<p>Note</p> <p>In general, the YouTube API is sometimes oddly limited for users that are not a content network. Some workarounds are necessary.</p> <p>Warning</p> <p>The Google-API wrapper currently does not work for macOS Sequoia, yet (22.09.2024).</p>"},{"location":"youtube/#preparations-prerequisites","title":"Preparations / Prerequisites","text":"<p>\ud83d\udc49A Google user account is required. \ud83d\udc49This user account needs to have access to the YouTube channel. \ud83d\udc49A Google Cloud Project with YouTube API V3 enabled. See the required API access below..</p> <p>\ud83d\udc49Add the YouTube channel id to the local configuration file `config_local.yaml.  <pre><code>youtube:\n  channels:\n    my_channel:\n      id: \"MYCHANNELID\"\n</code></pre> If unknown, one can retrieve the YouTube channel id via running:</p> <pre><code>from pytube.handlers.youtube import YT\n\nyt = YT()\nyt.get_channel_id()\n</code></pre>"},{"location":"youtube/#uploading-videos","title":"Uploading Videos","text":"<p>\ud83d\udc49Videos need to be uploaded via the \ud83d\udda5 YouTube studio web interface\ufe0f. By the way, API Uploads is not an option as they make videos 'private' by default,  and there is no way to change this setting afterward.</p> <p>Uploading is easy: one can upload 15 videos at a time by drag and drop.</p> <p>\ud83d\udc49All following steps are required:</p> <ol> <li>Include Pretix-Session-ID in file names, e.g., {PreTix-Session-ID}-{Title}.mp4.</li> <li>Make sure in YouTube Studio in Settings/Upload defaults the title is empty.    YouTube will use the filename as title then, we need this to match the descriptions' metadata to the video uploads.</li> <li>Add all videos uploaded to a hidden playlist (workaround)</li> </ol>"},{"location":"youtube/#youtube-video-ids-via-a-hidden-playlist","title":"YouTube Video IDs via a Hidden Playlist","text":"<p>After videos are uploaded to YouTube, we need to update the metadata. To update the metadata, we need the YouTube video ids.  </p> <p>Metadata of unpublished videos is not available via the YouTube API but can be retrieved via an unpublished playlist (workaround).</p> <p>Add the playlist id in the <code>local_config.yaml</code> file:</p> <pre><code>youtube:\n  channels:\n    my_channel:\n      playlist_id: \"playlist_id_ADD_HERE\"\n</code></pre>"},{"location":"youtube/#mapping-youtube-video-ids-to-pretalx-ids","title":"Mapping YouTube Video IDs to Pretalx IDs","text":"<p>You need to prepare mapping files for the processing pipeline. These files are expected by the handler (<code>Publisher</code>) by convention. </p> <p>The methods below create mappings of the pretalx id and the YouTube id and store them in JSON files.</p> <pre><code>from pytube.handlers.youtube import YT\n\nyt = YT()\nyt.get_youtube_ids_for_uploads(\"my_channel\")\n\n# Match the pretalx id with the YouTube video id\nyt.map_pretalx_id_youtube_id()\n</code></pre>"},{"location":"youtube/#caveats","title":"Caveats","text":"<p>\ud83d\udc49 It's impossible to get the filename used for the upload via the API, although the information is   available via the web interface. Do follow the steps above, step 2. \ud83d\udc49 API limits: Queries are limited per day, use them wisely.</p>"},{"location":"youtube/#youtube-descriptions","title":"YouTube Descriptions","text":"<p>The descriptions are generated via a jinja2 template. Please feel free to use the example in <code>/templates</code> as a starting point.</p> <p>If you use your own template, and require additional attributes, you can customize the <code>PrepareVideoMetadata</code> class. <code>scripts/youtube.py</code> provides an example of how to do this.</p> <pre><code>from pytube.handlers.youtube import PrepareVideoMetadata\n\nclass CustomPrepareVideoMetadata(PrepareVideoMetadata):\n    \"\"\"\n    Patch PrepareVideoMetadata to customize attributes used in the description template.\n    \"\"\"\n    @classmethod\n    def customize_description_args(cls, description_kwargs, record):\n        \"\"\"Customized the description arguments.\"\"\"\n        description_kwargs.update({\n            \"tag\": \"#great\",\n            \"pydata\": record.youtube_channel == \"pydata\"\n        })\n        return description_kwargs\n</code></pre>"},{"location":"youtube/#scheduling-videos","title":"Scheduling Videos","text":"<p>The <code>PrepareVideoMetadata</code> handler class provides a method to set the publishing date of the videos in the video metadata.</p> <pre><code>from datetime import datetime, timedelta, UTC\nfrom pytube.handlers.youtube import PrepareVideoMetadata\n\nmeta = PrepareVideoMetadata(\"template_file\", \"great conference name\")\n...\n# when to start and how often to publish\nin_five_minutes = datetime.now(UTC) + timedelta(minutes=5)\nevery_four_hours = timedelta(hours=4)\n\nmeta.update_publish_dates(start=in_five_minutes, delta=every_four_hours)\n</code></pre>"},{"location":"youtube/#api","title":"API","text":"<p>Access to the YouTube API V3 is required to update the metadata of the videos. To access the YouTube API V3 a Google Cloud project is required.</p>"},{"location":"youtube/#how-to-get-a-youtube-api-key","title":"How to Get a YouTube API Key","text":"<ol> <li>Log in to Google Developers Console.</li> <li>Create a new project.</li> <li>On the new project dashboard, click Explore &amp; Enable APIs.</li> <li>In the library, navigate to YouTube Data API v3 under YouTube APIs.</li> <li>Enable the YouTube API V3.</li> <li>Create credentials:     a. API key     b. OAuth2.0 client ID</li> </ol> <p>There are plenty of detailed tutorials available on the web.</p>"},{"location":"youtube/#caveats_1","title":"Caveats","text":"<p>\ud83d\udc49 Metadata updates require OAuth2.0 authentication. API keys or service accounts are not sufficient. \ud83d\udc49 Status updates can be requested with a simple API key.</p>"}]}